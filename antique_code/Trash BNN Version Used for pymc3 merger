from IPython import get_ipython
from IPython.display import display
# %%
# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.
import kagglehub
sumn2u_garbage_classification_v2_path = kagglehub.dataset_download('sumn2u/garbage-classification-v2')

print('Data source import complete.')

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
import numpy as np
import os
from torch.utils.data import DataLoader
from torch.amp import GradScaler, autocast  # Updated AMP import for eco-friendly training

# Define categories based on dataset
CATEGORIES = ["battery", "biological", "cardboard", "clothes", "glass",
              "metal", "paper", "plastic", "shoes", "trash"]

# Set device (use GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Detect if running in Kaggle (no internet allowed)
if "KAGGLE_KERNEL_RUN_TYPE" in os.environ:
    print("Running in Kaggle - Loading ResNet without pretrained weights")
    PRETRAINED_WEIGHTS = None  # No downloading allowed
else:
    print("Running in Colab - Loading ResNet with pretrained weights")
    PRETRAINED_WEIGHTS = models.ResNet50_Weights.DEFAULT  # Downloads weights

# Define dataset path - Fix applied for Kaggle dataset structure
DATASET_PATH = sumn2u_garbage_classification_v2_path + "/garbage-dataset"

# Print dataset structure to confirm correct path
print("Dataset contents:", os.listdir(DATASET_PATH))

# Define transformations for training images
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load dataset directly from garbage-dataset
train_dataset = datasets.ImageFolder(root=DATASET_PATH, transform=transform)

# Define DataLoader
BATCH_SIZE = 32
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)  # Reduced workers to 2

# Define Bayesian ResNet Model with Monte Carlo Dropout
class BayesianResNet(nn.Module):
    def __init__(self, num_classes=10):
        super(BayesianResNet, self).__init__()
        self.model = models.resnet50(weights=PRETRAINED_WEIGHTS)  # Uses pretrained weights if allowed
        self.model.fc = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(self.model.fc.in_features, num_classes)
        )

    def forward(self, x):
        return self.model(x)

# Initialize Model
model = BayesianResNet(num_classes=len(CATEGORIES)).to(device)

# Define Loss and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Set up automatic mixed precision scaler for eco-friendly training
scaler = torch.amp.GradScaler()  # ✅ Removed 'device_type' argument (now correct)

# Training Loop with Automatic Mixed Precision
num_epochs = 12  # Train for 12 epochs
checkpoint_interval = 1  # Save model every epoch (modify as needed)

# Define local checkpoint directory
LOCAL_CHECKPOINT_DIR = "local_checkpoints"

# Create the local checkpoint directory if it doesn't exist
if not os.path.exists(LOCAL_CHECKPOINT_DIR):
    os.makedirs(LOCAL_CHECKPOINT_DIR)

print(f"Starting epoch {1}/{num_epochs}...")  # Confirms Loop Run

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        # Use autocast to reduce power demands with mixed precision
        with torch.amp.autocast(device_type="cuda"):  # ✅ Fixed deprecated autocast usage
            outputs = model(images)
            loss = criterion(outputs, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        running_loss += loss.item()

    # Print epoch loss
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}")

    # Save checkpoint every epoch to local directory
    checkpoint_path = os.path.join(LOCAL_CHECKPOINT_DIR, f"resnet50_epoch{epoch+1}.pth")
    torch.save(model.state_dict(), checkpoint_path)
    print(f"Checkpoint saved at: {checkpoint_path}")

# Save Final Model to local directory
final_model_path = os.path.join(LOCAL_CHECKPOINT_DIR, "resnet50_final.pth")
torch.save(model.state_dict(), final_model_path)
print(f"Final model saved at: {final_model_path}")
